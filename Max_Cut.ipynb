{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8f70648",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2acb8ca",
   "metadata": {
    "id": "e2acb8ca"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from  numba import njit\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bda6947",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "uqgN4FodbFc0",
   "metadata": {
    "id": "uqgN4FodbFc0"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def graph_gen(model='ER', **kwargs):\n",
    "    # Extract the number of nodes 'n' from kwargs\n",
    "    n = kwargs['n']\n",
    "    \n",
    "    # If the model is 'ER' (Erdős-Rényi)\n",
    "    if model == 'ER':\n",
    "        # Extract the probability 'p' from kwargs\n",
    "        p = kwargs['p']\n",
    "        # Return an Erdős-Rényi graph\n",
    "        return nx.fast_gnp_random_graph(n, p)\n",
    "    \n",
    "    # If the model is 'BA' (Barabási-Albert)\n",
    "    elif model == 'BA':\n",
    "        # Extract the number of edges to attach from a new node 'm' from kwargs\n",
    "        m = kwargs['m']\n",
    "        # Return a Barabási-Albert graph\n",
    "        return nx.barabasi_albert_graph(n, m)\n",
    "    \n",
    "    # If the model is 'Watts_Strogatz' (Watts-Strogatz small-world)\n",
    "    elif model == 'Watts_Strogatz':\n",
    "        # Extract the number of nearest neighbors 'k' and the rewiring probability 'p' from kwargs\n",
    "        k = kwargs['k']\n",
    "        p = kwargs['p']\n",
    "        # Return a Watts-Strogatz graph\n",
    "        return nx.watts_strogatz_graph(n, k, p)\n",
    "    \n",
    "    # If an unknown model is provided, raise an error\n",
    "    else:\n",
    "        raise NotImplementedError('Unknown model of graph')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f7Ahgxqewiq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8f7Ahgxqewiq",
    "outputId": "dcec8c01-7a7a-4a79-a81b-66383cdb16f4"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import networkx as nx\n",
    "\n",
    "def flatten_graph(graph):\n",
    "    flat_adj_matrix = []\n",
    "    flat_weight_matrix = []\n",
    "    n = graph.number_of_nodes()\n",
    "    start = [0 for _ in range(n)]\n",
    "    end = [0 for _ in range(n)]\n",
    "    adj_list_dict = nx.to_dict_of_lists(graph)\n",
    "\n",
    "    # Assign random weights (1 or -1) to edges\n",
    "    for edge in graph.edges():\n",
    "#         graph.edges[edge]['weight'] = random.choice([1, -1])\n",
    "        graph.edges[edge]['weight'] = 1\n",
    "\n",
    "    for node, neighbors in adj_list_dict.items():\n",
    "        start[node] = len(flat_adj_matrix)\n",
    "        end[node] = start[node] + len(neighbors)\n",
    "        flat_adj_matrix += neighbors\n",
    "\n",
    "        # Build the flattened weight matrix\n",
    "        flat_weight_matrix += [graph.edges[(node, neighbor)]['weight'] for neighbor in neighbors]\n",
    "\n",
    "    return np.array(flat_adj_matrix), np.array(flat_weight_matrix), np.array(start), np.array(end)\n",
    "\n",
    "# Example usage with a random graph\n",
    "# G = nx.gnp_random_graph(5, 0.5, seed=42)\n",
    "# adj_matrix, weight_matrix, start_list, end_list = flatten_graph(G)\n",
    "\n",
    "# print(\"Flattened Adjacency Matrix:\", adj_matrix)\n",
    "# print(\"Flattened Weight Matrix:\", weight_matrix)\n",
    "# print(\"Start List:\", start_list)\n",
    "# print(\"End List:\", end_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "681c38c8",
   "metadata": {
    "id": "681c38c8"
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def ls_greedy(adj_matrix, weight_matrix, start_list, end_list,size_constraint):\n",
    "    \n",
    "    number_of_queries=0\n",
    "\n",
    "\n",
    "    n=len(start_list)\n",
    "    merginal_gain=np.zeros(n)\n",
    "    spins=np.zeros(n)\n",
    "\n",
    "\n",
    "    for i in range(n):\n",
    "        number_of_queries+=1\n",
    "        for j,weight in zip(adj_matrix[start_list[i]:end_list[i]],\n",
    "                  weight_matrix[start_list[i]:end_list[i]]):\n",
    "\n",
    "            merginal_gain[i]+=weight*(2*spins[i]-1)*(2*spins[j]-1)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    curr_score=0\n",
    "    step=0\n",
    "    \n",
    "    for _ in range(size_constraint):\n",
    "\n",
    "\n",
    "        max_gain = -np.inf\n",
    "        max_gain_node = -1\n",
    "\n",
    "        for i in range(len(spins)):\n",
    "            \n",
    "            if spins[i] == 0:\n",
    "                \n",
    "                number_of_queries+=1\n",
    "                \n",
    "                if merginal_gain[i] > max_gain:\n",
    "                    \n",
    "                    max_gain = merginal_gain[i]\n",
    "                    max_gain_node = i\n",
    "            \n",
    "\n",
    "\n",
    "        if merginal_gain[max_gain_node]<=0:\n",
    "            break\n",
    "        \n",
    "        \n",
    "#         assert spins[max_gain_node]==0\n",
    "        step+=1\n",
    "\n",
    "        curr_score+=merginal_gain[max_gain_node]\n",
    "        merginal_gain[max_gain_node]=-merginal_gain[max_gain_node]\n",
    "        for u,weight in zip(adj_matrix[start_list[max_gain_node]:end_list[max_gain_node]],\n",
    "                 weight_matrix[start_list[max_gain_node]:end_list[max_gain_node]]):\n",
    "            merginal_gain[u]+=weight*(2*spins[u]-1)*(2-4*spins[max_gain_node])\n",
    "\n",
    "        spins[max_gain_node] = 1-spins[max_gain_node]\n",
    "\n",
    "    return curr_score,spins,number_of_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "AtLhsBGpIcsW",
   "metadata": {
    "id": "AtLhsBGpIcsW"
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def fls_greedy(adj_matrix, weight_matrix, start_list, end_list,size_constraint,error_rate):\n",
    "    \n",
    "\n",
    "\n",
    "    n=len(start_list)\n",
    "    merginal_gain=np.zeros(n)\n",
    "    spins=np.zeros(n)\n",
    "    \n",
    "\n",
    "    number_of_queries=0\n",
    "    \n",
    "    # Calculate merginal gain for every element \n",
    "    for i in range(n):\n",
    "        number_of_queries+=1\n",
    "        for j,weight in zip(adj_matrix[start_list[i]:end_list[i]],\n",
    "                         weight_matrix[start_list[i]:end_list[i]]):\n",
    "            \n",
    "            merginal_gain[i]+=weight*(2*spins[i]-1)*(2*spins[j]-1)\n",
    "\n",
    "    # an approximation result\n",
    "\n",
    "    A_0=np.argmax(merginal_gain)\n",
    "    k=1\n",
    "    curr_score=merginal_gain[A_0]\n",
    "\n",
    "    merginal_gain[A_0]=-merginal_gain[A_0]\n",
    "    \n",
    "    for neighbour,weight in zip(adj_matrix[start_list[A_0]:end_list[A_0]],\n",
    "                     weight_matrix[start_list[A_0]:end_list[A_0]]):\n",
    "        \n",
    "        merginal_gain[neighbour]+=weight*(2*spins[neighbour]-1)*(2-4*spins[A_0])\n",
    "    spins[A_0]=1-spins[A_0]\n",
    "\n",
    "    # SWAP OR FLIP (ADD)\n",
    "\n",
    "    continue_search=True\n",
    "    \n",
    "\n",
    "    while continue_search:\n",
    "        best_spins=spins.copy()\n",
    "\n",
    "        continue_search=False\n",
    "\n",
    "        # EXCHANGE WITH DUMMY\n",
    "\n",
    "        if k<size_constraint:\n",
    "            for i in range(n):\n",
    "\n",
    "                if spins[i] == 0:\n",
    "                    number_of_queries+=1\n",
    "\n",
    "                    if merginal_gain[i]>=(error_rate/size_constraint)*curr_score:\n",
    "                        continue_search=True\n",
    "\n",
    "                        curr_score+=merginal_gain[i]\n",
    "                        merginal_gain[i]=-merginal_gain[i]\n",
    "\n",
    "\n",
    "                        for u,weight in zip(adj_matrix[start_list[i]:end_list[i]],\n",
    "                                         weight_matrix[start_list[i]:end_list[i]]):\n",
    "\n",
    "                            merginal_gain[u]+=weight*(2*spins[u]-1)*(2-4*spins[i])\n",
    "                        spins[i] = 1-spins[i]\n",
    "                        k+=1\n",
    "                        break\n",
    "\n",
    "\n",
    "        #SWAP\n",
    "        merginal_gain_copy=np.copy(merginal_gain)\n",
    "        spins_copy=np.copy(spins)\n",
    "\n",
    "        for e in range(n):\n",
    "\n",
    "            if continue_search==True:\n",
    "                break\n",
    "\n",
    "            merginal_gain=np.copy(merginal_gain_copy)\n",
    "            spins=np.copy(spins_copy)\n",
    "\n",
    "            # In the solution set\n",
    "            if spins[e]==1:\n",
    "#                 number_of_queries+=1\n",
    "                new_score=curr_score+merginal_gain[e] # (f(A-e))\n",
    "                merginal_gain[e]=-merginal_gain[e]\n",
    "\n",
    "\n",
    "                for u,weight in zip(adj_matrix[start_list[e]:end_list[e]],\n",
    "                                     weight_matrix[start_list[e]:end_list[e]]):\n",
    "                    merginal_gain[u]+=weight*(2*spins[u]-1)*(2-4*spins[e])\n",
    "                spins[e] = 1-spins[e]\n",
    "                \n",
    "\n",
    "                for a in range(n):\n",
    "                    if spins[a]==0:\n",
    "                        number_of_queries+=1 # (f(A-e+a))\n",
    "                        if new_score+merginal_gain[a]-curr_score>=(error_rate/size_constraint)*curr_score:\n",
    "\n",
    "    #                         print(swap)\n",
    "                            # Only if condition met then update\n",
    "                            continue_search=True\n",
    "                            #update\n",
    "                            curr_score=new_score+merginal_gain[a]\n",
    "                            merginal_gain[a]=-merginal_gain[a]\n",
    "                            # for u in range(n):\n",
    "                            for u,weight in zip(adj_matrix[start_list[a]:end_list[a]],\n",
    "                                            weight_matrix[start_list[a]:end_list[a]]):\n",
    "                                merginal_gain[u]+=weight*(2*spins[u]-1)*(2-4*spins[a])\n",
    "                            spins[a] = 1-spins[a]\n",
    "                            break\n",
    "                            \n",
    "        # DELETE \n",
    "        if continue_search is False:\n",
    "            merginal_gain=np.copy(merginal_gain_copy)\n",
    "            spins=np.copy(spins_copy)\n",
    "            \n",
    "            for d in range(n):\n",
    "                if spins[d]==1 :\n",
    "                    number_of_queries+=1\n",
    "                    if merginal_gain[d]>=(error_rate/size_constraint**4)*curr_score:\n",
    "                        continue_search=True\n",
    "                        curr_score+=merginal_gain[d]\n",
    "                        merginal_gain[d]=-merginal_gain[d]\n",
    "                        for u,weight in zip(adj_matrix[start_list[d]:end_list[d]],weight_matrix[start_list[d]:end_list[d]]):\n",
    "\n",
    "                            merginal_gain[u]+=weight*(2*spins[u]-1)*(2-4*spins[d])\n",
    "                        spins[d] = 1-spins[d]\n",
    "                        k-=1\n",
    "                        break\n",
    "                        \n",
    "        \n",
    "\n",
    "\n",
    "    best_score=curr_score\n",
    "    curr_score=0\n",
    "#     print(number_of_queries)\n",
    "\n",
    "    Z=best_spins.copy()\n",
    "\n",
    "    spins=np.zeros(n)\n",
    "    merginal_gain=np.zeros(n)\n",
    "    spins=np.zeros(n)\n",
    "    t=0.372\n",
    "    for i in range(n):\n",
    "        for j,weight in zip(adj_matrix[start_list[i]:end_list[i]],\n",
    "                     weight_matrix[start_list[i]:end_list[i]]):\n",
    "            merginal_gain[i]+=weight*(2*spins[i]-1)*(2*spins[j]-1)\n",
    "\n",
    "\n",
    "    for i in range(1,size_constraint+1):\n",
    "        arg_indices=np.argsort(-merginal_gain)\n",
    "\n",
    "        if i<=t*size_constraint:\n",
    "            \n",
    "            indices = [index for index in arg_indices if spins[index] == 0 and Z[index]==0]\n",
    "        else:\n",
    "            indices = [index for index in arg_indices if spins[index] == 0]\n",
    "        \n",
    "        \n",
    "        number_of_queries+=len(indices)\n",
    "        indices=indices[:size_constraint]\n",
    "        len_indices=len(indices)\n",
    "        \n",
    "        \n",
    "        add_element=False\n",
    "        for index in indices:\n",
    "            if merginal_gain[index]>0:\n",
    "                add_element=True\n",
    "                break\n",
    "        \n",
    "        if add_element:\n",
    "            \n",
    "\n",
    "            rand_idx=np.random.randint(len_indices)\n",
    "            rand_ele=indices[rand_idx]\n",
    "\n",
    "            if merginal_gain[rand_ele]<=0:\n",
    "                continue\n",
    "\n",
    "            curr_score+=merginal_gain[rand_ele]\n",
    "\n",
    "            merginal_gain[rand_ele]=-merginal_gain[rand_ele]\n",
    "            for u,weight in zip(adj_matrix[start_list[rand_ele]:end_list[rand_ele]],\n",
    "                            weight_matrix[start_list[rand_ele]:end_list[rand_ele]]):\n",
    "\n",
    "\n",
    "                merginal_gain[u]+=weight*(2*spins[u]-1)*(2-4*spins[rand_ele])\n",
    "            spins[rand_ele] = 1-spins[rand_ele]\n",
    "\n",
    "    \n",
    "    if best_score<curr_score:\n",
    "        best_spins=spins\n",
    "        \n",
    "    \n",
    "    return  max(best_score,curr_score),best_spins,number_of_queries,curr_score,spins\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66be2c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def random_greedy(adj_matrix, weight_matrix, start_list, end_list,size_constraint):\n",
    "    \n",
    "    number_of_queries=0\n",
    "    n=len(start_list)\n",
    "    merginal_gain=np.zeros(n)\n",
    "    spins=np.zeros(n)\n",
    "\n",
    "\n",
    "    for i in range(n):\n",
    "        number_of_queries+=1\n",
    "        for j,weight in zip(adj_matrix[start_list[i]:end_list[i]],\n",
    "                  weight_matrix[start_list[i]:end_list[i]]):\n",
    "\n",
    "            merginal_gain[i]+=weight*(2*spins[i]-1)*(2*spins[j]-1)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    curr_score=0\n",
    "    step=0\n",
    "    \n",
    "    for _ in range(size_constraint):\n",
    "        arg_indices=np.argsort(-merginal_gain)\n",
    "        \n",
    "        indices = [index for index in arg_indices if spins[index] == 0 and merginal_gain[index]>0]\n",
    "        number_of_queries+=(n-np.sum(spins))\n",
    "        indices=indices[:size_constraint]\n",
    "        len_indices=len(indices)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if indices:\n",
    "            rand_idx=np.random.randint(len_indices)\n",
    "            rand_ele=indices[rand_idx]\n",
    "            curr_score+=merginal_gain[rand_ele]\n",
    "\n",
    "            merginal_gain[rand_ele]=-merginal_gain[rand_ele]\n",
    "            for u,weight in zip(adj_matrix[start_list[rand_ele]:end_list[rand_ele]],\n",
    "                            weight_matrix[start_list[rand_ele]:end_list[rand_ele]]):\n",
    "\n",
    "\n",
    "                merginal_gain[u]+=weight*(2*spins[u]-1)*(2-4*spins[rand_ele])\n",
    "            spins[rand_ele] = 1-spins[rand_ele]\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        \n",
    "        \n",
    "    return curr_score,spins,number_of_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6b666cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def apx_local_search(adj_matrix, weight_matrix, start_list, end_list,size_constraint,error_rate,ground_set):\n",
    "    \n",
    "    n=len(start_list) # number of nodes\n",
    "    merginal_gain=np.zeros(n)\n",
    "    spins=np.zeros(n)\n",
    "\n",
    "    number_of_queries=0\n",
    "    \n",
    "    # Calculate merginal gain for every element in ground set\n",
    "    for i in range(n):\n",
    "        for j,weight in zip(adj_matrix[start_list[i]:end_list[i]],\n",
    "                         weight_matrix[start_list[i]:end_list[i]]):\n",
    "            \n",
    "            merginal_gain[i]+=weight*(2*spins[i]-1)*(2*spins[j]-1)\n",
    "    number_of_queries+=np.sum(ground_set)\n",
    "    # an approximation result\n",
    "    \n",
    "    max_gain=0\n",
    "    A_0=-1\n",
    "    for element in range(n):\n",
    "        if ground_set[element]==1:\n",
    "            if max_gain<merginal_gain[element]:\n",
    "                A_0=element\n",
    "                max_gain=merginal_gain[element]\n",
    "    k=1\n",
    "    curr_score=merginal_gain[A_0]\n",
    "\n",
    "    merginal_gain[A_0]=-merginal_gain[A_0]\n",
    "    \n",
    "    for neighbour,weight in zip(adj_matrix[start_list[A_0]:end_list[A_0]],\n",
    "                     weight_matrix[start_list[A_0]:end_list[A_0]]):\n",
    "        \n",
    "        merginal_gain[neighbour]+=weight*(2*spins[neighbour]-1)*(2-4*spins[A_0])\n",
    "    spins[A_0]=1-spins[A_0]\n",
    "    \n",
    "\n",
    "    # EXCHANGE or DELETE\n",
    "\n",
    "    continue_search=True\n",
    "    \n",
    "\n",
    "    while continue_search:\n",
    "        \n",
    "        best_spins=spins.copy()\n",
    "\n",
    "        continue_search=False\n",
    "                        \n",
    "\n",
    "        # EXCHANGE WITH DUMMY\n",
    "\n",
    "        if k<size_constraint and not continue_search:\n",
    "            for i in range(n):\n",
    "                if spins[i] == 0 and ground_set[i]==1:\n",
    "                    number_of_queries+=1\n",
    "                    if merginal_gain[i]>=(error_rate/size_constraint**4)*curr_score:\n",
    "                        continue_search=True\n",
    "                        curr_score+=merginal_gain[i]\n",
    "                        merginal_gain[i]=-merginal_gain[i]\n",
    "                        for u,weight in zip(adj_matrix[start_list[i]:end_list[i]],\n",
    "                                             weight_matrix[start_list[i]:end_list[i]]):\n",
    "\n",
    "                            merginal_gain[u]+=weight*(2*spins[u]-1)*(2-4*spins[i])\n",
    "                        spins[i] = 1-spins[i]\n",
    "                        k+=1\n",
    "                        break\n",
    "                        \n",
    "                                              \n",
    "\n",
    "        #EXCHANGE \n",
    "        merginal_gain_copy=np.copy(merginal_gain)\n",
    "        spins_copy=np.copy(spins)\n",
    "\n",
    "        for e in range(n):\n",
    "\n",
    "            if continue_search==True:\n",
    "                break\n",
    "\n",
    "            merginal_gain=np.copy(merginal_gain_copy)\n",
    "            spins=np.copy(spins_copy)\n",
    "\n",
    "            # In the solution set\n",
    "            if spins[e]==1 and ground_set[e]==1:\n",
    "                new_score=curr_score+merginal_gain[e] # (f(A-e))\n",
    "                merginal_gain[e]=-merginal_gain[e]\n",
    "\n",
    "\n",
    "                for u,weight in zip(adj_matrix[start_list[e]:end_list[e]],\n",
    "                                     weight_matrix[start_list[e]:end_list[e]]):\n",
    "                    merginal_gain[u]+=weight*(2*spins[u]-1)*(2-4*spins[e])\n",
    "                spins[e] = 1-spins[e]\n",
    "                \n",
    "\n",
    "                for a in range(n):\n",
    "                    if spins[a]==0 and ground_set[a]==1:\n",
    "                        number_of_queries+=1 # (f(A-e+a))\n",
    "                        if (new_score+merginal_gain[a])-curr_score>=(error_rate/size_constraint**4)*curr_score:\n",
    "                            continue_search=True\n",
    "                            #update\n",
    "                            curr_score=new_score+merginal_gain[a]\n",
    "                            merginal_gain[a]=-merginal_gain[a]\n",
    "                            for u,weight in zip(adj_matrix[start_list[a]:end_list[a]],\n",
    "                                            weight_matrix[start_list[a]:end_list[a]]):\n",
    "                                merginal_gain[u]+=weight*(2*spins[u]-1)*(2-4*spins[a])\n",
    "                            spins[a] = 1-spins[a]\n",
    "                            break\n",
    "                            \n",
    "        # DELETE \n",
    "        if continue_search is False:\n",
    "            merginal_gain=np.copy(merginal_gain_copy)\n",
    "            spins=np.copy(spins_copy)\n",
    "            \n",
    "            for d in range(n):\n",
    "                if spins[d]==1 and ground_set[i]==1:\n",
    "                    number_of_queries+=1\n",
    "                    if merginal_gain[d]>=(error_rate/size_constraint**4)*curr_score:\n",
    "                        continue_search=True\n",
    "                        curr_score+=merginal_gain[d]\n",
    "                        merginal_gain[d]=-merginal_gain[d]\n",
    "                        for u,weight in zip(adj_matrix[start_list[d]:end_list[d]],weight_matrix[start_list[d]:end_list[d]]):\n",
    "\n",
    "                            merginal_gain[u]+=weight*(2*spins[u]-1)*(2-4*spins[d])\n",
    "                        spins[d] = 1-spins[d]\n",
    "                        k-=1\n",
    "                        break\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "    return  curr_score,best_spins,number_of_queries\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13c07713",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def lee_ls(adj_matrix, weight_matrix, start_list, end_list,size_constraint,error_rate):\n",
    "    \n",
    "    n=len(start_list)\n",
    "    ground_set=np.ones(n,dtype=np.int32)\n",
    "    \n",
    "    \n",
    "    best_score_1,spins_1,number_of_queries_1=apx_local_search(adj_matrix, weight_matrix, start_list, \n",
    "                                                              end_list,size_constraint,error_rate,ground_set)\n",
    "\n",
    "    for i in range(n):\n",
    "        ground_set[i]=ground_set[i]-spins_1[i]\n",
    "#     ground_set=ground_set-spins_1\n",
    "    best_score_2,spins_2,number_of_queries_2=apx_local_search(adj_matrix, weight_matrix, start_list, \n",
    "                                                              end_list,size_constraint,error_rate,ground_set)\n",
    "    \n",
    "    number_of_queries=number_of_queries_1+number_of_queries_2\n",
    "    \n",
    "    \n",
    "    if best_score_1>best_score_2:\n",
    "        return best_score_1,spins_1,number_of_queries\n",
    "    else:\n",
    "        return best_score_2,spins_2,number_of_queries\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5824697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def get_adj_matrix(adj_matrix, weight_matrix, start_list, end_list ):\n",
    "    \n",
    "    n=len(start_list)\n",
    "    \n",
    "    G=np.zeros((n,n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j,weight in zip(adj_matrix[start_list[i]:end_list[i]],\n",
    "                     weight_matrix[start_list[i]:end_list[i]]):\n",
    "            G[i,j]=weight\n",
    "            \n",
    "            \n",
    "    return G\n",
    "            \n",
    "            \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06825d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_max_cut(G,spins,sol):\n",
    "    _temp=2*spins-1\n",
    "#     print((1/4) * np.sum( np.multiply( G, 1 - np.outer(_temp, _temp) ) ))\n",
    "    assert (1/4) * np.sum( np.multiply( G, 1 - np.outer(_temp, _temp) ) )==sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bee6f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# model = 'Watts_Strogatz'\n",
    "# number_of_nodes = 10000\n",
    "# m = 2\n",
    "# prob = 0.001\n",
    "# k = 10\n",
    "# size_constraint=5000\n",
    "\n",
    "# G = graph_gen(model=model, n=number_of_nodes, p=prob, m=m, k=k)\n",
    "# adj_matrix, weight_matrix, start_list, end_list = flatten_graph(G)\n",
    "# G=get_adj_matrix(adj_matrix, weight_matrix, start_list, end_list )\n",
    "# ls_sol, ls_spin, ls_quries = ls_greedy(adj_matrix, weight_matrix, start_list, end_list, \n",
    "#                                        size_constraint=size_constraint)\n",
    "# # check_max_cut(G,ls_spin,ls_sol)\n",
    "\n",
    "# fls_sol, fls_spin,fls_quries,guided_sol,guided_spin = fls_greedy(adj_matrix, weight_matrix, start_list,\n",
    "#                                                                  end_list, size_constraint=size_constraint,\n",
    "#                                                                  error_rate=0.01)\n",
    "# lee_sol, lee_spin,lee_quries = lee_ls(adj_matrix, weight_matrix, start_list,\n",
    "#                                                                  end_list, size_constraint=size_constraint,\n",
    "#                                                                error_rate=0.01)\n",
    "\n",
    "# rand_sol, rand_spin,rand_quries = random_greedy(adj_matrix, weight_matrix, start_list,\n",
    "#                                                                  end_list, size_constraint=size_constraint\n",
    "#                                                                )\n",
    "\n",
    "# # print('Random Greedy    ',rand_sol,np.sum(rand_spin))\n",
    "# # print('Standard Greedy  ',ls_sol,np.sum(ls_spin))\n",
    "# # print('Fast Local Search',fls_sol,np.sum(fls_spin))\n",
    "# # print('Lee et al.       ',lee_sol,np.sum(lee_spin))\n",
    "# # print(guided_sol,np.sum(guided_spin))\n",
    "# # check_max_cut(G,rand_spin,rand_sol)\n",
    "# # check_max_cut(G,lee_spin,lee_sol)\n",
    "# # check_max_cut(G,guided_spin,guided_sol)\n",
    "# # check_max_cut(G,fls_spin,fls_sol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eedbe46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs('MAX-CUT', exist_ok = True)\n",
    "os.makedirs('MAX-CUT/ER',exist_ok = True)\n",
    "os.makedirs('MAX-CUT/BA',exist_ok = True)\n",
    "os.makedirs('MAX-CUT/Watts_Strogatz',exist_ok = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cece9ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs:2\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from multiprocessing import Process\n",
    "\n",
    "def process_graph(graph_no,arg):\n",
    "    model = arg.get('model',None)\n",
    "    \n",
    "    number_of_nodes = arg.get('number_of_nodes',None)\n",
    "    m = arg.get('m',None)\n",
    "    prob = arg.get('p',None)\n",
    "    k = arg.get('k',None)\n",
    "\n",
    "    # Generate adj_matrix in the child process\n",
    "    G = graph_gen(model=model, n=number_of_nodes, p=prob, m=m, k=k)\n",
    "\n",
    "    save_folder=f'data/Maximum Cut/{model}'\n",
    "    os.makedirs(save_folder,exist_ok=True)\n",
    "    filename=f'{model}{number_of_nodes}_graph{str(graph_no).zfill(3)}.npy'\n",
    "    file_path=os.path.join(save_folder,filename)\n",
    "    np.save(file_path,G)\n",
    "    adj_matrix, weight_matrix, start_list, end_list = flatten_graph(G)\n",
    "    \n",
    "\n",
    "\n",
    "    df=defaultdict(list)\n",
    "    for mul in range(10,510,50):\n",
    "        \n",
    "        size_constraint=int(number_of_nodes*mul/1000)\n",
    "\n",
    "        \n",
    "        ls_sol, ls_spin,ls_queries= ls_greedy(adj_matrix, weight_matrix, start_list, end_list, size_constraint=size_constraint)\n",
    "        fls_sol, fls_spin,fls_queries,guided_sol,guided_spin = fls_greedy(adj_matrix, weight_matrix, \n",
    "                                                                         start_list, end_list, \n",
    "                                                                         size_constraint=size_constraint,\n",
    "                                                                         error_rate=0.01)\n",
    "        lee_sol, lee_spin, lee_queries = lee_ls(adj_matrix, weight_matrix, start_list,\n",
    "                                                                 end_list, size_constraint=size_constraint,\n",
    "                                                               error_rate=0.1)\n",
    "\n",
    "        rand_sol, rand_spin,rand_queries= random_greedy(adj_matrix, weight_matrix, start_list,\n",
    "                                                                 end_list, size_constraint=size_constraint\n",
    "                                                               )\n",
    "        \n",
    "       \n",
    "        df['graph no'].append(graph_no)\n",
    "        df['k'].append(size_constraint)\n",
    "        df['greedy'].append(ls_sol)\n",
    "        df['fls'].append(fls_sol)\n",
    "        df['lee'].append(lee_sol)\n",
    "        df['rand'].append(rand_sol)\n",
    "\n",
    "        df['greedy_quries'].append(ls_queries)\n",
    "        df['fls_quries'].append(fls_queries)\n",
    "        df['lee_quries'].append(lee_queries)\n",
    "        df['rand_quries'].append(rand_queries)\n",
    "        \n",
    "    df=pd.DataFrame(df)\n",
    "    df.to_pickle(f\"MAX-CUT/{model}/{graph_no}.pkl\")\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # Record the start time using perf_counter()\n",
    "    from collections import defaultdict\n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    \n",
    "    number_of_graphs = 2\n",
    "    print(f\"Number of graphs:{number_of_graphs}\")\n",
    "    processes = []\n",
    "\n",
    "    \n",
    "#     args ={'model':'ER','number_of_nodes':10000,'p':0.001}\n",
    "#     title = f\"Erdős-Rényi Model: {args['number_of_nodes']} Nodes, p={args['p']}\"\n",
    "#     args ={'model':'BA','number_of_nodes':10000,'m':2}\n",
    "#     title = f\"Barabási-Albert Model: {args['number_of_nodes']} Nodes, m={args['m']}\"\n",
    "    args ={'model':'Watts_Strogatz','number_of_nodes':10000,'k':10,'p':0.001}\n",
    "    title=f\"Watts-Strogatz Model: {args['number_of_nodes']} Nodes, k={args['k']}, p={args['p']}\"\n",
    "    \n",
    "\n",
    "\n",
    "    for graph_no in range(number_of_graphs):\n",
    "        process = Process(target=process_graph, args=(graph_no,args))\n",
    "        processes.append(process)\n",
    "        process.start()\n",
    "\n",
    "    for process in processes:\n",
    "        process.join()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e560c063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# model = 'Watts_Strogatz'\n",
    "# root_folder = f'MAX-CUT/{model}'\n",
    "# dataframe = None\n",
    "\n",
    "# # Load and concatenate dataframes from pickles in the root folder\n",
    "# for file in os.listdir(root_folder):\n",
    "#     df_loaded = pd.read_pickle(os.path.join(root_folder, file))\n",
    "#     if dataframe is not None:\n",
    "#         dataframe = pd.concat([dataframe, df_loaded], ignore_index=True)\n",
    "#     else:\n",
    "#         dataframe = df_loaded\n",
    "\n",
    "# # Group by 'k' and compute mean and standard deviation\n",
    "# result = dataframe.groupby('k').mean().reset_index()\n",
    "# result_std = dataframe.groupby('k').std().reset_index()\n",
    "\n",
    "# number_of_nodes = 10000\n",
    "\n",
    "# # Plotting the first set of data\n",
    "# plt.figure(dpi=200)\n",
    "\n",
    "# # FastLS+GuidedRG\n",
    "# plt.plot(result['k'] / number_of_nodes, result['fls'] / result['greedy'], \n",
    "#          label='FastLS+GuidedRG', marker='*', linestyle='-', color='blue', markersize=16)\n",
    "# plt.fill_between(result['k'] / number_of_nodes, \n",
    "#                  (result['fls'] / result['greedy']) - (result_std['fls'] / result['greedy'] / 2),\n",
    "#                  (result['fls'] / result['greedy']) + (result_std['fls'] / result['greedy'] / 2),\n",
    "#                  color='blue', alpha=0.2)\n",
    "\n",
    "# # Random Greedy\n",
    "# plt.plot(result['k'] / number_of_nodes, result['rand'] / result['greedy'], \n",
    "#          label='Random Greedy', marker='.', linestyle='--', color='green', markersize=16)\n",
    "# plt.fill_between(result['k'] / number_of_nodes, \n",
    "#                  (result['rand'] / result['greedy']) - (result_std['rand'] / result['greedy'] / 2),\n",
    "#                  (result['rand'] / result['greedy']) + (result_std['rand'] / result['greedy'] / 2),\n",
    "#                  color='green', alpha=0.2)\n",
    "\n",
    "# # Lee et al.\n",
    "# plt.plot(result['k'] / number_of_nodes, result['lee'] / result['greedy'], \n",
    "#          label='Lee et al.', marker='.', linestyle='-', color='red', markersize=16)\n",
    "# plt.fill_between(result['k'] / number_of_nodes, \n",
    "#                  (result['lee'] / result['greedy']) - (result_std['lee'] / result['greedy'] / 2),\n",
    "#                  (result['lee'] / result['greedy']) + (result_std['lee'] / result['greedy'] / 2),\n",
    "#                  color='red', alpha=0.2)\n",
    "\n",
    "# # Add labels and title\n",
    "# plt.xlabel('k/n', fontsize=26)\n",
    "# plt.ylabel('Objective / Greedy', fontsize=26)\n",
    "# plt.xticks(fontsize=26)\n",
    "# plt.yticks(fontsize=26)\n",
    "# # plt.legend(loc='lower left', fontsize=26, framealpha=0.0)\n",
    "# plt.grid(True, linestyle='--', alpha=0.7)\n",
    "# plt.savefig(f'ObjectiveMC{model}.pdf', dpi=300, bbox_inches='tight')\n",
    "# plt.show()\n",
    "\n",
    "# # Plotting the second set of data\n",
    "# plt.figure(dpi=200)\n",
    "\n",
    "# # FastLS+GuidedRG Queries\n",
    "# plt.plot(result['k'] / number_of_nodes, result['fls_quries'] / result['greedy_quries'], \n",
    "#          label='FastLS+GuidedRG', marker='*', linestyle='-', color='blue', markersize=16)\n",
    "# plt.fill_between(result['k'] / number_of_nodes, \n",
    "#                  (result['fls_quries'] / result['greedy_quries']) - (result_std['fls_quries'] / result['greedy_quries'] / 2),\n",
    "#                  (result['fls_quries'] / result['greedy_quries']) + (result_std['fls_quries'] / result['greedy_quries'] / 2),\n",
    "#                  color='blue', alpha=0.2)\n",
    "\n",
    "# # Random Queries\n",
    "# plt.plot(result['k'] / number_of_nodes, result['rand_quries'] / result['greedy_quries'], \n",
    "#          label='Random', marker='.', linestyle='--', color='green', markersize=16)\n",
    "# plt.fill_between(result['k'] / number_of_nodes, \n",
    "#                  (result['rand_quries'] / result['greedy_quries']) - (result_std['rand_quries'] / result['greedy_quries'] / 2),\n",
    "#                  (result['rand_quries'] / result['greedy_quries']) + (result_std['rand_quries'] / result['greedy_quries'] / 2),\n",
    "#                  color='green', alpha=0.2)\n",
    "\n",
    "# # Lee et al. Queries\n",
    "# plt.plot(result['k'] / number_of_nodes, result['lee_quries'] / result['greedy_quries'], \n",
    "#          label='Lee et al.', marker='.', linestyle='-', color='red', markersize=16)\n",
    "# plt.fill_between(result['k'] / number_of_nodes, \n",
    "#                  (result['lee_quries'] / result['greedy_quries']) - (result_std['lee_quries'] / result['greedy_quries'] / 2),\n",
    "#                  (result['lee_quries'] / result['greedy_quries']) + (result_std['lee_quries'] / result['greedy_quries'] / 2),\n",
    "#                  color='red', alpha=0.2)\n",
    "\n",
    "# # Add labels and title\n",
    "# plt.xlabel('k/n', fontsize=26)\n",
    "# plt.ylabel('Queries / Greedy', fontsize=26)\n",
    "# plt.xticks(fontsize=26)\n",
    "# plt.yticks(fontsize=26)\n",
    "# # plt.legend(loc='lower left', fontsize=26, framealpha=0.0)\n",
    "# plt.grid(True, linestyle='--', alpha=0.7)\n",
    "# plt.savefig(f'QueriesMC{model}.pdf', dpi=300, bbox_inches='tight')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a8f90bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# from multiprocessing import Process\n",
    "\n",
    "# def solve(adj_matrix, weight_matrix, start_list, end_list, size_constraint,model,rep):\n",
    "\n",
    "#     df=defaultdict(list)\n",
    "\n",
    "#     ls_sol, ls_spin,ls_queries= ls_greedy(adj_matrix, weight_matrix, start_list, end_list, size_constraint=size_constraint)\n",
    "#     fls_sol, fls_spin,fls_queries,guided_sol,guided_spin = fls_greedy(adj_matrix, weight_matrix, \n",
    "#                                                                         start_list, end_list, \n",
    "#                                                                         size_constraint=size_constraint,\n",
    "#                                                                         error_rate=0.01)\n",
    "#     lee_sol, lee_spin, lee_queries = lee_ls(adj_matrix, weight_matrix, start_list,\n",
    "#                                             end_list, size_constraint=size_constraint,\n",
    "#                                             error_rate=0.01)\n",
    "\n",
    "#     rand_sol, rand_spin,rand_queries= random_greedy(adj_matrix, weight_matrix, start_list,\n",
    "#                                                                 end_list, size_constraint=size_constraint\n",
    "#                                                             )\n",
    "    \n",
    "    \n",
    "#     df['k'].append(size_constraint)\n",
    "#     df['greedy'].append(ls_sol)\n",
    "#     df['fls'].append(fls_sol)\n",
    "#     df['lee'].append(lee_sol)\n",
    "#     df['rand'].append(rand_sol)\n",
    "\n",
    "#     df['greedy_quries'].append(ls_queries)\n",
    "#     df['fls_quries'].append(fls_queries)\n",
    "#     df['lee_quries'].append(lee_queries)\n",
    "#     df['rand_quries'].append(rand_queries)\n",
    "        \n",
    "#     df=pd.DataFrame(df)\n",
    "#     df.to_pickle(f\"MAX-CUT/{model}/{size_constraint}_{rep}.pkl\")\n",
    "        \n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "\n",
    "#     # Record the start time using perf_counter()\n",
    "#     from collections import defaultdict\n",
    "#     start_time = time.perf_counter()\n",
    "    \n",
    "    \n",
    "#     number_of_graphs = 1\n",
    "#     print(f\"Number of graphs:{number_of_graphs}\")\n",
    "#     processes = []\n",
    "\n",
    "    \n",
    "# #     args ={'model':'ER','number_of_nodes':10000,'p':0.001}\n",
    "# #     title = f\"Erdős-Rényi Model: {args['number_of_nodes']} Nodes, p={args['p']}\"\n",
    "# #     args ={'model':'BA','number_of_nodes':10000,'m':2}\n",
    "# #     title = f\"Barabási-Albert Model: {args['number_of_nodes']} Nodes, m={args['m']}\"\n",
    "#     args ={'model':'Watts_Strogatz','number_of_nodes':10000,'k':10,'p':0.001}\n",
    "#     title=f\"Watts-Strogatz Model: {args['number_of_nodes']} Nodes, k={args['k']}, p={args['p']}\"\n",
    "\n",
    "#     model = args.get('model',None)\n",
    "    \n",
    "#     number_of_nodes = args.get('number_of_nodes',None)\n",
    "#     m = args.get('m',None)\n",
    "#     prob = args.get('p',None)\n",
    "#     k = args.get('k',None)\n",
    "\n",
    "#     # Generate adj_matrix in the child process\n",
    "#     G = graph_gen(model=model, n=number_of_nodes, p=prob, m=m, k=k)\n",
    "#     adj_matrix, weight_matrix, start_list, end_list = flatten_graph(G)\n",
    "\n",
    "#     np.save(f'{model}.npy', G)\n",
    "#     processes = []\n",
    "#     num_rep=10\n",
    "\n",
    "#     for rep in range(num_rep):\n",
    "#         for mul in range(10,510,50):\n",
    "#             size_constraint=int(number_of_nodes*mul/1000)\n",
    "#             process = Process(target=solve, args=(adj_matrix, weight_matrix, start_list, end_list, \n",
    "#                                                         size_constraint,model,rep))\n",
    "#             processes.append(process)\n",
    "#             process.start()\n",
    "\n",
    "\n",
    "\n",
    "#     for process in processes:\n",
    "#         process.join()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f171de21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import glob\n",
    "\n",
    "# model='Watts_Strogatz'\n",
    "\n",
    "# root_folder=f'MAX-CUT/{model}'\n",
    "# dataframe=None\n",
    "# for file in os.listdir(root_folder):\n",
    "#     df_loaded = pd.read_pickle(os.path.join(root_folder,file))\n",
    "#     if dataframe is not None:\n",
    "#         dataframe=pd.concat([dataframe,df_loaded], ignore_index=True)\n",
    "#     else:\n",
    "#         dataframe=df_loaded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45ac0495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_fls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f18324c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_lee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa97ca6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_rand = []\n",
    "# mean_fls = []\n",
    "# mean_lee = []\n",
    "\n",
    "# mean_quieres_rand = []\n",
    "# mean_quieres_fls = []\n",
    "# mean_quieres_lee = []\n",
    "\n",
    "# x_axis = []\n",
    "# for k, group_df in dataframe.groupby('k'):\n",
    "#     # Compute mean and std for the group\n",
    "#     mean = group_df.mean(axis=0)\n",
    "#     std = group_df.std(axis=0)\n",
    "    \n",
    "#     # Append normalized k value\n",
    "#     x_axis.append(k / number_of_nodes)\n",
    "    \n",
    "#     # Append normalized means for 'rand', 'fls', and 'lee' over 'greedy'\n",
    "#     mean_rand.append(mean['rand'] / mean['greedy'])\n",
    "#     mean_fls.append(mean['fls'] / mean['greedy'])\n",
    "#     mean_lee.append(mean['lee'] / mean['greedy'])\n",
    "\n",
    "#     # Append normalized means for 'rand_quries', 'fls_quries', and 'lee_quries' over 'greedy_quries'\n",
    "#     mean_quieres_rand.append(mean['rand_quries'] / mean['greedy_quries'])\n",
    "#     mean_quieres_fls.append(mean['fls_quries'] / mean['greedy_quries'])\n",
    "#     mean_quieres_lee.append(mean['lee_quries'] / mean['greedy_quries'])\n",
    "\n",
    "#     # Uncomment if you want to debug and see the means and stds\n",
    "#     # print(group_df.mean(axis=0))\n",
    "#     # print(group_df.std(axis=0))\n",
    "\n",
    "# print(model)\n",
    "# plt.figure(dpi=200)\n",
    "# number_of_nodes=10000\n",
    "# plt.plot(x_axis, \n",
    "#          mean_fls, \n",
    "#          label='FastLS+GuidedRG', marker='*', linestyle='-', color='blue',markersize=16)\n",
    "# plt.plot(x_axis, mean_rand, \n",
    "#          label='Random Greedy', marker='.', \n",
    "#          linestyle='--', color='green',markersize=16)\n",
    "# plt.plot(x_axis, mean_lee, label='Lee et al.', \n",
    "#          marker='.', linestyle='-', color='red',markersize=16)\n",
    "# # plt.plot(result['k']/number_of_nodes, result['guided_random']/result['greedy'], label='Guided Random Greedy', marker='o', linestyle='-', color='red')\n",
    "# # plt.plot(result['k'], result['greedy'], label='Greedy', marker='o', linestyle='-', color='red')\n",
    "\n",
    "\n",
    "# # Add labels and title\n",
    "# plt.xlabel('k/n',fontsize=26)\n",
    "# # plt.ylabel('Determinant')\n",
    "# plt.ylabel('Objective / Greedy',fontsize=26)\n",
    "# plt.xticks(fontsize=26)\n",
    "# plt.yticks(fontsize=26)\n",
    "# # plt.legend()\n",
    "\n",
    "# # plt.title(title)\n",
    "\n",
    "# # # Add a legend\n",
    "# plt.legend(loc='lower left',fontsize=\"26\", framealpha=0.0)\n",
    "\n",
    "# # Customize the grid lines\n",
    "# plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# # Save the plot to a file (optional)\n",
    "# plt.savefig(f'ObjectiveMC{model}.pdf', dpi=300,bbox_inches='tight')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n",
    "\n",
    "# # print(model)\n",
    "# # plt.figure(dpi=200)\n",
    "# # number_of_nodes=10000\n",
    "# # plt.plot(result['k']/number_of_nodes, result['fls_quries']/result['greedy_quries'], \n",
    "# #          label='FastLS+GuidedRG', marker='*', linestyle='-', color='blue',markersize=16)\n",
    "# # plt.plot(result['k']/number_of_nodes, \n",
    "# #          result['rand_quries']/result['greedy_quries'], \n",
    "# #          label='Random', marker='.', \n",
    "# #          linestyle='--', color='green',markersize=16)\n",
    "# # plt.plot(result['k']/number_of_nodes, \n",
    "# #          result['lee_quries']/result['greedy_quries'], \n",
    "# #          label='Lee et al.', \n",
    "# #          marker='.', linestyle='-', color='red',markersize=16)\n",
    "\n",
    "# # plt.xlabel('k/n',fontsize=26)\n",
    "# # # plt.ylabel('Determinant')\n",
    "# # plt.ylabel('Queries / Greedy',fontsize=26)\n",
    "# # plt.xticks(fontsize=26)\n",
    "# # plt.yticks(fontsize=26)\n",
    "\n",
    "# # # plt.title(title)\n",
    "\n",
    "# # # # Add a legend\n",
    "# # # plt.legend(fontsize=\"16\")\n",
    "\n",
    "# # # Customize the grid lines\n",
    "# # plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# # # plt.title(f'Max Cut ER{number_of_nodes} Error Rate {0.1}')\n",
    "\n",
    "# # # Add a legend\n",
    "# # # plt.legend()\n",
    "# # # plt.title(title)\n",
    "# # # Customize the grid lines\n",
    "# # plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "\n",
    "# # # Save the plot to a file (optional)\n",
    "# # plt.savefig(f'QueriesMC{model}.pdf', dpi=300,bbox_inches='tight')\n",
    "\n",
    "# # # Show the plot\n",
    "# # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f8c07c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # dataframe=pd.DataFrame(df)\n",
    "\n",
    "# # print(title)\n",
    "\n",
    "# result = dataframe.groupby('k').mean().reset_index()\n",
    "# # result=result.drop('Graph No', axis=1)\n",
    "# print(model)\n",
    "# plt.figure(dpi=200)\n",
    "# number_of_nodes=10000\n",
    "# plt.plot(result['k']/number_of_nodes, \n",
    "#          result['fls']/result['greedy'], \n",
    "#          label='FastLS+GuidedRG', marker='*', linestyle='-', color='blue',markersize=16)\n",
    "# plt.plot(result['k']/number_of_nodes, result['rand']/result['greedy'], \n",
    "#          label='Random Greedy', marker='.', \n",
    "#          linestyle='--', color='green',markersize=16)\n",
    "# plt.plot(result['k']/number_of_nodes, result['lee']/result['greedy'], label='Lee et al.', \n",
    "#          marker='.', linestyle='-', color='red',markersize=16)\n",
    "# # plt.plot(result['k']/number_of_nodes, result['guided_random']/result['greedy'], label='Guided Random Greedy', marker='o', linestyle='-', color='red')\n",
    "# # plt.plot(result['k'], result['greedy'], label='Greedy', marker='o', linestyle='-', color='red')\n",
    "\n",
    "\n",
    "# # Add labels and title\n",
    "# plt.xlabel('k/n',fontsize=26)\n",
    "# # plt.ylabel('Determinant')\n",
    "# plt.ylabel('Objective / Greedy',fontsize=26)\n",
    "# plt.xticks(fontsize=26)\n",
    "# plt.yticks(fontsize=26)\n",
    "# # plt.legend()\n",
    "\n",
    "# # plt.title(title)\n",
    "\n",
    "# # # Add a legend\n",
    "# plt.legend(loc='lower left',fontsize=\"26\", framealpha=0.0)\n",
    "\n",
    "# # Customize the grid lines\n",
    "# plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# # Save the plot to a file (optional)\n",
    "# plt.savefig(f'ObjectiveMC{model}.pdf', dpi=300,bbox_inches='tight')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n",
    "\n",
    "# print(model)\n",
    "# plt.figure(dpi=200)\n",
    "# number_of_nodes=10000\n",
    "# plt.plot(result['k']/number_of_nodes, result['fls_quries']/result['greedy_quries'], \n",
    "#          label='FastLS+GuidedRG', marker='*', linestyle='-', color='blue',markersize=16)\n",
    "# plt.plot(result['k']/number_of_nodes, \n",
    "#          result['rand_quries']/result['greedy_quries'], \n",
    "#          label='Random', marker='.', \n",
    "#          linestyle='--', color='green',markersize=16)\n",
    "# plt.plot(result['k']/number_of_nodes, \n",
    "#          result['lee_quries']/result['greedy_quries'], \n",
    "#          label='Lee et al.', \n",
    "#          marker='.', linestyle='-', color='red',markersize=16)\n",
    "\n",
    "# plt.xlabel('k/n',fontsize=26)\n",
    "# # plt.ylabel('Determinant')\n",
    "# plt.ylabel('Queries / Greedy',fontsize=26)\n",
    "# plt.xticks(fontsize=26)\n",
    "# plt.yticks(fontsize=26)\n",
    "\n",
    "# # plt.title(title)\n",
    "\n",
    "# # # Add a legend\n",
    "# # plt.legend(fontsize=\"16\")\n",
    "\n",
    "# # Customize the grid lines\n",
    "# plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# # plt.title(f'Max Cut ER{number_of_nodes} Error Rate {0.1}')\n",
    "\n",
    "# # Add a legend\n",
    "# # plt.legend()\n",
    "# # plt.title(title)\n",
    "# # Customize the grid lines\n",
    "# plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "\n",
    "# # Save the plot to a file (optional)\n",
    "# plt.savefig(f'QueriesMC{model}.pdf', dpi=300,bbox_inches='tight')\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
